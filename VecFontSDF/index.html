<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style type="text/css">
div.content{
	text-align:center;
	margin:auto;
	max-width:900px;
}

h1{
    margin-left: auto;
    margin-right: auto;
    width: 95%;
    line-height:150%;
    text-align: center;
    font-size:20pt;
    font-family:Arial, Serif;
}
h2{
    margin-left: -4px;
    margin-right: auto;
    width: 95%;
    line-height:150%;
    text-align: justify;
    font-size:20pt;
    font-family:Arial, Serif;
}

div.authors{
	font-weight:bold;
    text-align: center;
    width: 90%;
    margin: auto;
    font-family: Arial, Serif;
    font-size:12pt;
}

div.hints1{
	text-align:center;
	font-size:8pt;
}

div.icst{
	text-align:center;
	font-size:11pt;
}

div.acc{
	font-style:italic;
	text-align:center;
	font-size:12pt;
}

div.plaintext{
	text-align: justify;
}

td{
	text-align:center;
	font-size:15pt;
}

img{
	width:100%;
	margin:auto;
}
</style>
</head>
<body>
	<div id="main">
		<div class="content">
			<h1>VecFontSDF: Learning to Reconstruct and Synthesize High-quality Vector Fonts via Signed Distance Functions.</h1><br/>
			<div class="authors">
				<a href="https://xiazeqing.github.io" style="text-decoration: none">Zeqing Xia</a><sup>1</sup>&nbsp;&nbsp;				
				<a href="https://xiazeqing.github.io" style="text-decoration: none">Bojun Xiong</a><sup>1</sup>&nbsp;&nbsp;
				<a href="http://www.icst.pku.edu.cn/zlian/" style="text-decoration: none">Zhouhui Lian<sup>2</sup></a>&nbsp;&nbsp;
			</div>
			<div class="hints1"><sup>1</sup>Equal contribution.&nbsp;&nbsp;<sup>2</sup>Corresponding author.</div>
			<br>
			<div class="icst"><a href="http://www.wict.pku.edu.cn/english/home/index.htm" style="text-decoration: none">Wangxuan Institute of Computer Technology, Peking University, Beijing, P.R. China<br/>Center For Chinese Font Design and Research, Peking University, Beijing, P.R. China</a></div>
			<br>
			<div class="acc"><i>Accepted by CVPR, Jun. 2023.</i></div>
			<br>
			<img src="./images/teaser.svg" style="width:60%"/>
			<h2>Abstract</h2>
			<div class="plaintext">
				Font design is of vital importance in the digital content design and modern printing industry. Developing algorithms capable of automatically synthesizing vector fonts can significantly facilitate the font design process. However, existing methods mainly concentrate on raster image generation, and only a few approaches can directly synthesize vector fonts. This paper proposes an end-to-end trainable method, VecFontSDF, to reconstruct and synthesize high-quality vector fonts using signed distance functions (SDFs). Specifically, based on the proposed SDF-based implicit shape representation, VecFontSDF learns to model each glyph as shape primitives enclosed by several parabolic curves, which can be precisely converted to quadratic BÃ©zier curves that are widely used in vector font products. In this manner, most image generation methods can be easily extended to synthesize vector fonts. Qualitative and quantitative experiments conducted on a publicly-available dataset demonstrate that our method obtains high-quality results on several tasks, including vector font reconstruction, interpolation, and few-shot vector font synthesis, markedly outperforming the state of the art.
			</div>
			<h2>Method Overview</h2>
			<img src="./images/method.svg"/>
			<h2>Download</h2>
			<div class="plaintext">
			<li>Paper: <a href="https://arxiv.org/abs/2303.12675">arxiv</a> or <a href="./documents/paper.pdf">PDF</a></li>
			<li>Supplemental materials: <a href="./documents/supp.pdf">PDF</a></li>
			<h2>Results</h2>
			<h3>Reconstruction</h3>
			<img src="./images/recon.svg"/>
			<h3>Interpolation</h3>
			<img src="./images/interpolation.svg"/>
			<h3>Few-shot Generation</h3>
			<img src="./images/fewshot.svg"/>
			<h2>Citation</h2>
			// Will be updated after CVPR conference
			<div class="plaintext">
				@InProceedings{Xia_2023_CVPR,
				    author    = {Xia, Zeqing and Xiong, Bojun and Lian, Zhouhui},
				    title     = {VecFontSDF: Learning To Reconstruct and Synthesize High-Quality Vector Fonts via Signed Distance Functions},
				    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
				    month     = {June},
				    year      = {2023},
				    pages     = {1848-1857}
				}<br/>
			</div>
			<!---
			<img src="./images/figure3.png"/>
			<h2>Abstract</h2>
			<div class="plaintext">
			Despite the recent impressive development of deep neural networks, using deep learning based methods to generate large-scale Chinese fonts is still a rather challenging task due to the huge number of intricate Chinese glyphs, e.g., the official standard Chinese charset GB18030-2000 consists of 27,533 Chinese characters. Until now, most existing models for this task adopt Convolutional Neural Networks (CNNs) to generate bitmap images of Chinese characters due to CNN based models' remarkable success in various applications. However, CNN based models focus more on image-level features while usually ignore stroke order information when writing characters. Instead, we treat Chinese characters as sequences of points (i.e., writing trajectories) and propose to handle this task via an effective Recurrent Neural Network (RNN) model with monotonic attention mechanism, which can learn from as few as hundreds of training samples and then synthesize glyphs for remaining thousands of characters in the same style. Experimental results show that our proposed FontRNN can be used for synthesizing large-scale Chinese fonts as well as generating realistic Chinese handwritings efficiently.
			</div>
			<h2>Download</h2>
			<div class="plaintext">
			<li>Paper: <a href="./documents/paper.pdf">PDF</a></li>
			<li>Supplemental materials: <a href="./documents/supp.zip">ZIP</a></li>
			
			<li>Code & Dataset: <a href="https://github.com/ShusenTang/FontRNN">Github</a></li>
			</div>
			<h2>Experimental Results</h2>
			<table>
			<tr> 
			<td>
			<br>
			Generated Skeletons
			</td>
			</tr>
			<tr>
			<td>
			<img src="./images/figure7.png"/>
			</td>
			</tr>
			<tr> 
			<td>
			<br>
			Character Synthesis
			</td>
			</tr>
			<tr>
			<td>
			<img src="./images/figure8.png"/>
			</td>
			</tr>
			</table>
			<table>
			<tr> 
			<td style="width:50%">
			<br>
			Details at the Intersections
			</td>
			<td style="width:50%">
			<br>
			Comparsion with [ZYZ* 18]
			</td>
			</tr>
			<tr>
			<td style="width:50%">
			<img src="./images/figure9.png"/>
			</td>
			<td style="width:50%">
			<img src="./images/figure11.png"/>
			</td>
			</table>
			<h2>Citation</h2>
			<div class="plaintext">
			@article{CGF38-7:567-577:2019,<br/>
			    journal = {Computer Graphics Forum},<br/>
			    title = {{FontRNN: Generating Large-scale Chinese Fonts via Recurrent Neural Network}},<br/>
			    author = {Shusen Tang and Zeqing Xia and Zhouhui Lian and Yingmin Tang and Jianguo Xiao},<br/>
			    pages = {567-577},<br/>
			    volume= {38},<br/>
			    number= {7},<br/>
			    year = {2019},<br/>
			    note = {\URL{https://diglib.eg.org/bitstream/handle/10.1111/cgf13861/v38i7pp567-577.pdf}},<br/>
			    DOI = {10.1111/cgf.13861},<br/>
			}<br/>
			</div>
			-->
			
		</div>
	</div>
</body>
